{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Classifing student success data by means of the [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) from the sklearn module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data/ Data Transformation\n",
    "For fitting a multi-layer perception model for classification it is suggested that you standardize the design matrix otherwise optimization of the weights are less likely to converge in fewer iterations. Hence after importing the data and converting the response class labels, we scale the design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "df = pd.read_csv('student-por2.csv')\n",
    "df = pd.get_dummies(df)#, drop_first=True)\n",
    "\n",
    "def response_conv(arr):\n",
    "    new = []\n",
    "    for i in arr:\n",
    "        if (i > 0 and i < 10):           # condition where student failed\n",
    "            new.append(0)                 \n",
    "                                          \n",
    "        elif (i >= 10):                   # condition where student passed\n",
    "            new.append(1)                 \n",
    "    \n",
    "        else:                             # condition where student received an incomplete\n",
    "            new.append(2)\n",
    "    return(new)                           # 1-dimensional response varibale returned\n",
    "\n",
    "X = df.drop('G3',1)                       # This is the design matrix\n",
    "y = list(df.G3)                           # This is the discrete response vector\n",
    "y_new = response_conv(y)                  # This is the multinomial response vector\n",
    "X_scale = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Parameters for NN\n",
    "Here we use 10-fold cross validation to make sure that we return the model with the best accuracy. We also print out the values for each parameter that make the model optimal. Lastly return the run time of the cross validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters for standardized design matrix are as follows: \n",
      "Hidden layer size: 30 \n",
      "Activation function: relu \n",
      "Solver for weight optimization: sgd \n",
      "Learning rate: constant \n",
      "Alpha(penalty parameter): 0.1\n",
      "Cross Validation took 0.3 minutes.\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_scale, y_new, test_size=0.33, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "combos = cartesian([['constant'],['sgd'],['logistic', 'tanh', 'relu'],10.0**-np.arange(1,7)])\n",
    "in_layer_size = len(list(X))\n",
    "out_layer_size = 3\n",
    "hidden_layer_size = int((in_layer_size+out_layer_size)/2)\n",
    "\n",
    "def opt(X,y):\n",
    "    acc = []\n",
    "    for learn,solver,act,alpha in combos:\n",
    "        nn = MLPClassifier(hidden_layer_sizes=(hidden_layer_size,),activation=act,solver=solver,learning_rate=learn,alpha=float(alpha),learning_rate_init = 0.2,random_state=42)\n",
    "        scores = cross_val_score(nn, X, y, cv=10, scoring='accuracy')\n",
    "        acc.append(scores.mean())\n",
    "    \n",
    "\n",
    "    opt_ = combos[acc.index(max(acc))]\n",
    "    return(opt_)\n",
    "\n",
    "lea1,sol1,act1,alp1 = opt(X1_train,y1_train)\n",
    "\n",
    "print(\"Optimal parameters for standardized design matrix are as follows: \\nHidden layer size: %r \\nActivation function: %s \\nSolver for weight optimization: %s \\nLearning rate: %s \\nAlpha(penalty parameter): %r\" % (hidden_layer_size,act1,sol1,lea1,float(alp1)))\n",
    "print(\"Cross Validation took %r minutes.\" % (int(time.time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Plot the Cost Function for Stochastic Gradient Descent\n",
    "Here we fit the model with the optimal parameters found in the last section. We return a plot of the Cost Function converging to its minimum after a specific number of iterations. As expected we see convergance and have a good model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc1648d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4d21b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp1 = MLPClassifier(hidden_layer_sizes=(hidden_layer_size,),activation=act1,solver=sol1,learning_rate=lea1,learning_rate_init = 0.2,alpha=float(alp1),random_state=42)\n",
    "nn1 = mlp1.fit(X1_train,y1_train)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"SGD Cost Function\")\n",
    "plt.xlabel(\"Number of Iterations for SGD\")\n",
    "plt.ylabel(\"Cost Function\")\n",
    "plt.plot(nn1.loss_curve_, 'r-', label='Standardized Matrix')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Layers and Weighted Coefficients\n",
    "This step is to get an idea of the weighted coefficients used for each neuron in the *hidden* and *outside* layers. The hidden layer is denoted by *0* and the outside layer is denoted by *1*. **Note** In this example we only have one hidden layer and one outside layer. In previous steps we found the best number of neurons on the hidden layer was 30, thus in the hidden layer the first neuron is denoted by *0* and the last neuron is denoted by *29*. For each neuron in every layer the *SGD* optimal weights array is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer, Neuron, and Weights for standardized design matrix.\n",
      "Layer: 0 \n",
      "Neuron: 0 \n",
      "Weights: array([ 0.06263697,  0.05439814, -0.08611071, -0.46551536,  0.00519754,\n",
      "        0.17871103,  0.04394986, -0.16128204, -0.002872  ,  0.30853032,\n",
      "        0.19546622, -0.1225424 , -0.01181599,  0.4176992 ,  0.55058984,\n",
      "        0.19304923, -0.07992313, -0.04546058,  0.20336475,  0.12319385,\n",
      "       -0.21142383, -0.07111921,  0.09044346, -0.04996244,  0.12287251,\n",
      "       -0.16602844,  0.20532183,  0.40171683, -0.52355455,  0.00257011,\n",
      "        0.05142041, -0.11362136,  0.08033124, -0.1779292 ,  0.00948104,\n",
      "       -0.09483933,  0.23532698,  0.09106091,  0.16840675, -0.16157959,\n",
      "        0.10606762,  0.38399262, -0.02008588, -0.07287674, -0.15368455,\n",
      "        0.18544389, -0.01277256, -0.16270904,  0.07319994,  0.0762067 ,\n",
      "       -0.02320797, -0.02398815,  0.15988566, -0.14712526,  0.10064224,\n",
      "       -0.23939304,  0.10254465, -0.24219741]), \n",
      "Layer: 0 \n",
      "Neuron: 1 \n",
      "Weights: array([ 0.16671758, -0.07002302, -0.13160149,  0.10343281, -0.07161443,\n",
      "       -0.24559022, -0.04648578,  0.0022082 ,  0.07302297,  0.05809343,\n",
      "        0.04390339, -0.05133708,  0.08446328,  0.15722883,  0.26385351,\n",
      "        0.05467328,  0.01604777,  0.0095421 , -0.00274759,  0.1396482 ,\n",
      "       -0.12232825,  0.08149678,  0.16385279, -0.08875436, -0.02069449,\n",
      "        0.09334486, -0.03261621,  0.01762877,  0.17860701, -0.04217896,\n",
      "       -0.14385705, -0.00929818, -0.02718113,  0.18103544, -0.08810508,\n",
      "        0.14905748, -0.12467968, -0.20408064, -0.10406713,  0.18489246,\n",
      "       -0.16651827, -0.09971133,  0.0736676 , -0.09306944, -0.15791269,\n",
      "        0.08506934, -0.0540429 , -0.08425289, -0.09249556,  0.04584495,\n",
      "        0.1604361 , -0.13552731,  0.00803817,  0.05544073, -0.27560459,\n",
      "        0.09842715,  0.14915742, -0.13887291]), \n",
      "Layer: 0 \n",
      "Neuron: 2 \n",
      "Weights: array([-0.21500182, -0.10310808,  0.11021564, -0.00712255, -0.16097078,\n",
      "       -0.2848745 ,  0.2654892 ,  0.03951073,  0.30213156,  0.14369506,\n",
      "        0.03603582, -0.11568333,  0.07207597, -0.14272586, -0.13833756,\n",
      "        0.18278003, -0.21651563,  0.03077515,  0.01412832,  0.02983802,\n",
      "       -0.14850186, -0.13250545,  0.16518793,  0.00560967, -0.12411952,\n",
      "       -0.09200831, -0.07789341,  0.01009557, -0.03334464, -0.03910618,\n",
      "       -0.20325448,  0.1531482 , -0.00812893, -0.05754997,  0.07913411,\n",
      "        0.12695794,  0.05638025, -0.17708219,  0.03927681, -0.0059405 ,\n",
      "       -0.10087609, -0.06587235, -0.04975828,  0.01578329,  0.13131678,\n",
      "       -0.0449446 ,  0.05798299,  0.00856664, -0.04626439,  0.19961939,\n",
      "       -0.23569669,  0.16384747,  0.1456617 , -0.17100584, -0.04179774,\n",
      "       -0.00678416,  0.01195   ,  0.10540237]), \n",
      "Layer: 0 \n",
      "Neuron: 3 \n",
      "Weights: array([  6.33200497e-02,   2.78233389e-01,  -1.53887772e-01,\n",
      "        -1.05377771e-01,  -1.65380024e-02,   8.13034515e-02,\n",
      "         3.09352070e-01,   1.18455490e-01,  -1.66890825e-02,\n",
      "         1.66830366e-02,   4.05684996e-03,  -8.17111775e-02,\n",
      "        -1.67025172e-01,  -5.78978512e-01,  -1.01129720e+00,\n",
      "        -1.33756097e-01,   2.82323539e-01,   3.70196980e-02,\n",
      "         1.12619639e-01,   9.96161143e-02,  -1.80092422e-01,\n",
      "         2.10940886e-02,  -8.52778778e-02,  -7.06273544e-02,\n",
      "         6.60444888e-02,   3.29815341e-02,   3.81336935e-03,\n",
      "        -3.95251954e-02,   1.15869716e-01,   9.38280446e-02,\n",
      "        -1.33021030e-01,   1.03708017e-01,   6.58236840e-02,\n",
      "        -3.10558481e-02,   1.21672089e-01,  -3.77749337e-02,\n",
      "         1.37245349e-01,   8.57681344e-02,   7.36606541e-02,\n",
      "        -8.05018857e-02,  -3.67416246e-02,  -1.29848548e-01,\n",
      "        -6.19351824e-02,   1.02195524e-01,   3.12580451e-02,\n",
      "        -4.67094643e-02,  -6.85607054e-02,  -1.21987328e-01,\n",
      "        -4.13881483e-02,  -9.38103258e-04,  -7.16175499e-02,\n",
      "        -3.58271694e-02,   4.97444076e-03,  -1.77798479e-01,\n",
      "         3.24604975e-02,   5.59604423e-02,   1.59964507e-02,\n",
      "         6.25515644e-02]), \n",
      "Layer: 0 \n",
      "Neuron: 4 \n",
      "Weights: array([-0.19029041,  0.18837431,  0.14109574,  0.09555549, -0.05346908,\n",
      "        0.02915281,  0.00460544,  0.06617866, -0.16088954,  0.07595655,\n",
      "        0.02289093, -0.15003434,  0.14950306,  0.09464671, -0.0426573 ,\n",
      "        0.01530813, -0.10003557, -0.06845376, -0.02522393,  0.01646469,\n",
      "       -0.02119526, -0.1362144 , -0.08390335, -0.04944949, -0.03700368,\n",
      "       -0.11045354, -0.09108511,  0.07724225, -0.09721456, -0.07765841,\n",
      "       -0.04392495, -0.07022398, -0.08376459, -0.00852595,  0.12523908,\n",
      "        0.06100024,  0.13582169,  0.07604954, -0.0222395 ,  0.18513502,\n",
      "       -0.15342332,  0.06700074, -0.10527867,  0.05302312,  0.11729005,\n",
      "        0.01141555,  0.0766134 , -0.02432629,  0.12108294, -0.06677307,\n",
      "        0.00456332, -0.06195629,  0.01109006,  0.14110611, -0.1251349 ,\n",
      "       -0.07995916, -0.08386361, -0.14133687]), \n",
      "Layer: 0 \n",
      "Neuron: 5 \n",
      "Weights: array([-0.14243723,  0.07693613,  0.02840792,  0.04117467, -0.10385063,\n",
      "       -0.06975376,  0.00176773, -0.10109368,  0.16463047, -0.01661036,\n",
      "        0.14565158, -0.14396327,  0.01578337,  0.14347849,  0.04015182,\n",
      "        0.00902027,  0.10055453, -0.10531638, -0.0659455 ,  0.09073807,\n",
      "        0.02343257,  0.01498775, -0.12621692,  0.00671802,  0.1191812 ,\n",
      "        0.05385088,  0.02536757,  0.04105032, -0.00129933, -0.07086863,\n",
      "        0.18498687, -0.08610468, -0.09804537, -0.07420775, -0.02210481,\n",
      "        0.00066275, -0.00954804, -0.01344096,  0.08237884, -0.01526505,\n",
      "        0.11414843, -0.06374504, -0.07446372, -0.12794471, -0.13462465,\n",
      "        0.1931484 , -0.07601062,  0.14885838, -0.09879114,  0.05558909,\n",
      "       -0.02916026, -0.10420815, -0.02481179,  0.02540315,  0.05453762,\n",
      "        0.11992216,  0.09211283,  0.14632437]), \n",
      "Layer: 0 \n",
      "Neuron: 6 \n",
      "Weights: array([-0.12186476, -0.13628858, -0.19903273,  0.00327139,  0.1325503 ,\n",
      "       -0.01806341,  0.05048694, -0.23535323, -0.06870877,  0.13460745,\n",
      "        0.08504613,  0.25253344,  0.09456169,  0.28376497,  0.14379593,\n",
      "        0.16347497, -0.42593149, -0.07350366, -0.06840402, -0.21457624,\n",
      "        0.03465417, -0.10743261,  0.04581849, -0.14460714, -0.01444649,\n",
      "        0.23489366,  0.18788629, -0.20552358, -0.14107165,  0.0556055 ,\n",
      "        0.11071169, -0.16600444,  0.06363379,  0.14188363,  0.04625012,\n",
      "        0.12107864,  0.05377087, -0.17535811,  0.05100922,  0.12477264,\n",
      "       -0.01491426,  0.14359441, -0.01355266, -0.10888917, -0.07331956,\n",
      "        0.09636514,  0.12319465, -0.17528062,  0.00755479,  0.13170742,\n",
      "        0.08157455, -0.14798959, -0.00552151, -0.01069822, -0.06620061,\n",
      "       -0.00204701,  0.21598292, -0.22139852]), \n",
      "Layer: 0 \n",
      "Neuron: 7 \n",
      "Weights: array([ 0.07373311, -0.10243326,  0.04871568, -0.01914977,  0.12769616,\n",
      "        0.2009528 ,  0.06842135,  0.12536404,  0.25050085,  0.07053228,\n",
      "       -0.01982122,  0.0532898 ,  0.21931466, -0.15936137,  0.12798274,\n",
      "       -0.01459832, -0.05507181,  0.07883656,  0.05532083,  0.1052776 ,\n",
      "       -0.02434308, -0.09456231, -0.07151772, -0.00897209,  0.11373919,\n",
      "       -0.0040305 , -0.01411122, -0.04662015,  0.17570504,  0.03056341,\n",
      "       -0.08453737,  0.11791809, -0.09730495, -0.02336938,  0.07355686,\n",
      "       -0.02666679, -0.11220427,  0.04247147,  0.11059035, -0.1278033 ,\n",
      "       -0.01084887,  0.0168095 ,  0.00900039, -0.12461631,  0.06422713,\n",
      "       -0.00539718, -0.07031725, -0.13754889, -0.03890602,  0.20597452,\n",
      "       -0.03911128,  0.09885977, -0.06144964, -0.16812896, -0.07244396,\n",
      "        0.02829828, -0.01895539,  0.06962607]), \n",
      "Layer: 0 \n",
      "Neuron: 8 \n",
      "Weights: array([ 0.19117707,  0.15384243, -0.09000658, -0.03578402, -0.09133715,\n",
      "       -0.16799807,  0.15965724,  0.13377082, -0.01020476, -0.03882559,\n",
      "       -0.0081466 , -0.00113429, -0.36004597,  0.27074696, -0.20202844,\n",
      "       -0.26244872,  0.26431718,  0.06601995,  0.07522124,  0.12323943,\n",
      "       -0.12448227,  0.08923695, -0.24066417,  0.09759706, -0.27680043,\n",
      "        0.01079115, -0.18545036,  0.03177686, -0.13677915,  0.07731055,\n",
      "        0.05404847, -0.18522298, -0.23888326,  0.28626149,  0.12526366,\n",
      "       -0.12187073,  0.14770552,  0.20921318,  0.01763111,  0.27773474,\n",
      "       -0.25601644,  0.13564934, -0.00269136,  0.06848658,  0.12340734,\n",
      "       -0.14134532,  0.0871375 ,  0.03029456, -0.01836795,  0.22495726,\n",
      "        0.05966452, -0.11828219, -0.08708226,  0.00625209,  0.15980626,\n",
      "       -0.3007019 ,  0.09268365,  0.07147185]), \n",
      "Layer: 0 \n",
      "Neuron: 9 \n",
      "Weights: array([-0.01332084, -0.09900708,  0.1810441 , -0.18043038,  0.03991316,\n",
      "        0.11264917, -0.16054108,  0.14034931,  0.34037689,  0.14632642,\n",
      "        0.0479287 , -0.14088532, -0.14078866,  0.03457535, -0.09155528,\n",
      "       -0.14948881,  0.1520159 , -0.18553677,  0.16403696, -0.03757627,\n",
      "        0.02328452, -0.03842612, -0.05552082, -0.05679152, -0.04204817,\n",
      "        0.19637595,  0.16298282, -0.07504133, -0.00154349, -0.17760128,\n",
      "       -0.08914262,  0.0334876 ,  0.00698134,  0.02295877,  0.03753624,\n",
      "        0.04551221, -0.10714612,  0.00680273,  0.03987965,  0.04366875,\n",
      "        0.11224883, -0.09458395, -0.08974403,  0.08922599,  0.0106644 ,\n",
      "        0.0145311 ,  0.03943516,  0.06843707,  0.02636748,  0.00669875,\n",
      "        0.07623122,  0.00447768, -0.1292456 ,  0.22551265, -0.07902338,\n",
      "        0.05052199,  0.14740614, -0.1462959 ]), \n",
      "Layer: 0 \n",
      "Neuron: 10 \n",
      "Weights: array([-0.16298882, -0.19386859,  0.10963148, -0.21237675, -0.07017135,\n",
      "       -0.14268594, -0.22933479, -0.09257447, -0.07325491,  0.15984909,\n",
      "       -0.05114637, -0.06939683,  0.11545973, -0.14934567, -0.02322795,\n",
      "       -0.10168055, -0.01708632,  0.21835267, -0.18654896, -0.22894811,\n",
      "        0.08938532, -0.13250722, -0.09192628, -0.03140669, -0.05294692,\n",
      "       -0.12999784, -0.0606639 ,  0.03853485, -0.0645147 , -0.06315344,\n",
      "        0.00680043, -0.07855891,  0.00283046, -0.0324191 , -0.11210815,\n",
      "        0.2334801 ,  0.19651153, -0.10285401, -0.01157325,  0.11272743,\n",
      "        0.04043721,  0.0159287 ,  0.06108732, -0.137173  , -0.02122811,\n",
      "        0.15137863,  0.01946954, -0.14407335, -0.01088107,  0.09853604,\n",
      "       -0.06432425,  0.20958581, -0.01129875, -0.05034297,  0.11239101,\n",
      "       -0.01311898, -0.08181876, -0.10820956]), \n",
      "Layer: 0 \n",
      "Neuron: 11 \n",
      "Weights: array([ 0.13689727, -0.07019965, -0.15581927,  0.01667329, -0.01709578,\n",
      "       -0.03982026,  0.16846351, -0.01427214, -0.11812946,  0.00367684,\n",
      "       -0.1746648 ,  0.02103608, -0.20734691,  0.20479214,  0.1590347 ,\n",
      "        0.2869238 , -0.21197596, -0.08182929,  0.14668442,  0.03627353,\n",
      "        0.18061568, -0.15244854,  0.21334463, -0.18485211,  0.14767585,\n",
      "       -0.23900804, -0.02289767, -0.05426565,  0.17694513,  0.05868629,\n",
      "       -0.05101956, -0.05567144,  0.09497682,  0.07233844,  0.00807248,\n",
      "        0.18356044, -0.01364618,  0.09720319,  0.11379445, -0.11503475,\n",
      "        0.10329928, -0.01893323,  0.13723807,  0.08435144,  0.12031071,\n",
      "       -0.13982689, -0.07182155, -0.04484484,  0.16401795, -0.23690688,\n",
      "       -0.02829946, -0.02039635, -0.2449936 ,  0.10346569,  0.03893964,\n",
      "       -0.07699168, -0.00739383, -0.09724623]), \n",
      "Layer: 0 \n",
      "Neuron: 12 \n",
      "Weights: array([ 0.08397504, -0.11042054, -0.20775204,  0.00322647, -0.19258843,\n",
      "        0.19429031,  0.26948075, -0.20535612,  0.16975018,  0.0127486 ,\n",
      "       -0.04968368, -0.0899883 ,  0.08306272, -0.10279735,  0.08578803,\n",
      "        0.06094111, -0.05442253,  0.09997884,  0.04522407, -0.03551304,\n",
      "        0.06904873, -0.07300844, -0.12408947, -0.13833156,  0.13883285,\n",
      "       -0.13019636,  0.0060603 ,  0.00919445, -0.0873217 , -0.13748655,\n",
      "       -0.02716319,  0.01453892,  0.07421339,  0.13091659, -0.0602524 ,\n",
      "        0.09156871,  0.07416553, -0.01992871,  0.08130873, -0.0863946 ,\n",
      "        0.05030132,  0.01972843,  0.08673759, -0.13353503, -0.12546484,\n",
      "        0.08412107, -0.07961404, -0.13984248,  0.03421944,  0.08081234,\n",
      "        0.12164767,  0.0238376 ,  0.1966126 , -0.20676077, -0.09152043,\n",
      "        0.25410983, -0.18504255,  0.10210333]), \n",
      "Layer: 0 \n",
      "Neuron: 13 \n",
      "Weights: array([-0.04823085,  0.09344945,  0.15604462, -0.14885278,  0.01309409,\n",
      "       -0.08851194, -0.05667506, -0.25491028, -0.08109449, -0.13556518,\n",
      "        0.14682628,  0.03851515,  0.06999789,  0.37887973,  0.12399865,\n",
      "       -0.01101974, -0.05256588,  0.20046167, -0.08830633, -0.03063147,\n",
      "       -0.1334009 , -0.03840162, -0.00277869, -0.14978211,  0.05447191,\n",
      "        0.11729127, -0.02764869, -0.01469202,  0.03876945, -0.05309889,\n",
      "       -0.02467727,  0.12994135, -0.06942777,  0.03054409, -0.09166092,\n",
      "       -0.08142834, -0.01153748,  0.07576679,  0.14336713,  0.31104439,\n",
      "       -0.10953662,  0.12347562, -0.19473069,  0.07811538,  0.02310468,\n",
      "        0.15161427,  0.07833715, -0.17068747,  0.03306669, -0.15094718,\n",
      "       -0.23202236,  0.03022562, -0.08457685,  0.14518042,  0.04419688,\n",
      "        0.03717061, -0.14239772, -0.0670166 ]), \n",
      "Layer: 0 \n",
      "Neuron: 14 \n",
      "Weights: array([-0.03709595, -0.05481676,  0.10559376,  0.17774968,  0.04167622,\n",
      "       -0.10081249, -0.08109653, -0.10568293, -0.08109997,  0.10506486,\n",
      "        0.13132676, -0.02423987, -0.06896247,  0.02074837, -0.00694539,\n",
      "        0.1822642 , -0.06376058,  0.05224565,  0.14670662, -0.01897833,\n",
      "        0.16005136, -0.1820689 ,  0.05133009, -0.12831424, -0.03246391,\n",
      "       -0.08264521, -0.11137416, -0.07791163, -0.04352286,  0.09127939,\n",
      "        0.10957909, -0.09666519, -0.10084056,  0.01077459, -0.12594603,\n",
      "       -0.02439357, -0.12159372,  0.13930091,  0.01052604, -0.08409807,\n",
      "        0.03172395,  0.06810092,  0.09450325, -0.04175387,  0.13929863,\n",
      "        0.05768462, -0.06981149,  0.15986627, -0.12716517, -0.05232124,\n",
      "       -0.07002381,  0.11418531, -0.02914318, -0.16949021,  0.0924766 ,\n",
      "        0.16333944, -0.11397833,  0.13058938]), \n",
      "Layer: 0 \n",
      "Neuron: 15 \n",
      "Weights: array([ 0.04595962,  0.03445597,  0.01871746, -0.0391859 ,  0.00153469,\n",
      "        0.16485958, -0.11116688, -0.19563375,  0.022059  , -0.00387575,\n",
      "        0.1010012 , -0.03459512,  0.07721561,  0.04779261,  0.0696317 ,\n",
      "        0.00276138, -0.07838659,  0.0448512 , -0.08041972,  0.01317501,\n",
      "        0.03163015,  0.06104502,  0.18185135,  0.16800221,  0.07329551,\n",
      "        0.04340969, -0.02789477,  0.1382721 , -0.0632889 , -0.07382034,\n",
      "        0.02878608, -0.11750967,  0.00469592, -0.09670441,  0.11218268,\n",
      "       -0.07947378, -0.03565314,  0.08425143,  0.13636803,  0.04162926,\n",
      "        0.05147357, -0.06830529, -0.21187456,  0.20516825,  0.00152532,\n",
      "       -0.06221607,  0.03231583,  0.18862461,  0.10546925, -0.02271135,\n",
      "       -0.18647094,  0.04486589, -0.06740427, -0.03978931, -0.05656568,\n",
      "        0.08051485, -0.06746954, -0.17448908]), \n",
      "Layer: 0 \n",
      "Neuron: 16 \n",
      "Weights: array([-0.15719737, -0.07680378,  0.19198229, -0.02917341,  0.02529958,\n",
      "        0.0273247 ,  0.24260034,  0.17285959,  0.20433597,  0.13711153,\n",
      "       -0.0403883 , -0.10719579,  0.44454543, -0.31638313, -0.28277805,\n",
      "        0.02016862, -0.05651846, -0.1215086 , -0.00403346, -0.09324259,\n",
      "       -0.14691368,  0.11378325, -0.1956948 , -0.00874335, -0.07061721,\n",
      "        0.00614707,  0.16801843,  0.03155221, -0.06738581, -0.10645485,\n",
      "       -0.10261568, -0.01895068,  0.09423653,  0.01754854, -0.13838264,\n",
      "       -0.28464698,  0.03927742, -0.16659339,  0.079171  , -0.00178615,\n",
      "       -0.12011821, -0.00091481, -0.0292287 ,  0.0170219 , -0.15041553,\n",
      "        0.12686551, -0.1509698 , -0.00601786,  0.17367472, -0.14982784,\n",
      "        0.02110692,  0.1050757 , -0.21075468, -0.04211541, -0.18273042,\n",
      "        0.0736035 , -0.19281383,  0.06348722]), \n",
      "Layer: 0 \n",
      "Neuron: 17 \n",
      "Weights: array([ 0.03099516, -0.05934242, -0.14042772,  0.14286554,  0.01625919,\n",
      "       -0.22843412, -0.03921762, -0.03061679,  0.04064715, -0.18278767,\n",
      "       -0.19145279, -0.1234899 , -0.12692877,  0.00880365,  0.30695538,\n",
      "        0.35493823, -0.36987149, -0.07116431, -0.12300963, -0.46913061,\n",
      "        0.30377559, -0.10254139,  0.12395584,  0.24933525, -0.0750115 ,\n",
      "        0.09923736, -0.07214421, -0.042041  ,  0.11554732, -0.1510549 ,\n",
      "        0.08738456, -0.03677714,  0.07063759, -0.06876504,  0.12417475,\n",
      "       -0.05969195, -0.06552442, -0.01489314,  0.01760735, -0.16430972,\n",
      "        0.11219741, -0.16982779,  0.06495063,  0.15442838,  0.11737451,\n",
      "        0.04659425,  0.03521501,  0.02058373,  0.07122794,  0.03228005,\n",
      "        0.11464286,  0.01008997, -0.03209519,  0.15517818, -0.17599998,\n",
      "        0.19909884, -0.13325235,  0.16994483]), \n",
      "Layer: 0 \n",
      "Neuron: 18 \n",
      "Weights: array([-0.02539006, -0.05506762, -0.03412553, -0.06455182,  0.02272286,\n",
      "       -0.17158347,  0.13961996,  0.25502088,  0.12719935, -0.05899513,\n",
      "       -0.13475815, -0.25111156,  0.01068312,  0.31690599,  0.30086839,\n",
      "       -0.17705788,  0.23215111, -0.24341539,  0.19096659, -0.18640208,\n",
      "        0.16810556,  0.02857064,  0.18253035, -0.13361745,  0.04840688,\n",
      "       -0.04570918, -0.17122458,  0.19648349,  0.02954409, -0.13899346,\n",
      "        0.13546428, -0.00532104, -0.16174784,  0.11535679, -0.11376339,\n",
      "       -0.02014968,  0.0628906 ,  0.03744015,  0.03907283, -0.1431414 ,\n",
      "        0.01938233,  0.31465601, -0.05540844, -0.08874627, -0.17346352,\n",
      "       -0.03470927,  0.06784701,  0.00346173, -0.07508381, -0.03504296,\n",
      "       -0.01884275, -0.17958717,  0.02904487, -0.07334245,  0.29134544,\n",
      "       -0.26105667,  0.06171588,  0.1545173 ]), \n",
      "Layer: 0 \n",
      "Neuron: 19 \n",
      "Weights: array([-0.19364831, -0.16191963, -0.21482683, -0.11758816,  0.04893575,\n",
      "        0.02963643,  0.08856527, -0.13112498, -0.27640182,  0.01955709,\n",
      "       -0.06346136, -0.06832555,  0.12589149, -0.23220162,  0.02169282,\n",
      "       -0.00662706,  0.27081807,  0.16828094, -0.03331508, -0.25087563,\n",
      "        0.22309464,  0.05958179,  0.04169141, -0.04906893,  0.06533254,\n",
      "        0.09223087,  0.2019494 ,  0.01341718, -0.12239797, -0.18506576,\n",
      "       -0.07751024,  0.07830505,  0.04209504,  0.00504401, -0.16552916,\n",
      "       -0.06981725, -0.0201061 , -0.08340259, -0.12765798, -0.00949852,\n",
      "       -0.02089157,  0.07068835,  0.10209138, -0.01479696, -0.19327273,\n",
      "       -0.01036041,  0.12032631,  0.03958949,  0.17713367, -0.14719852,\n",
      "        0.21934647, -0.06346813,  0.04329396, -0.01916607,  0.15095923,\n",
      "        0.05619296, -0.09334852,  0.13919186]), \n",
      "Layer: 0 \n",
      "Neuron: 20 \n",
      "Weights: array([ 0.02204176,  0.12436331,  0.14740616, -0.02961583,  0.10592234,\n",
      "        0.02466032, -0.02642854,  0.05798323,  0.01905204, -0.12176627,\n",
      "       -0.01943908, -0.02380869, -0.05267767, -0.09940887, -0.10169373,\n",
      "       -0.10950243,  0.02889449,  0.14643119, -0.00257519, -0.10261636,\n",
      "       -0.08566999, -0.16520143,  0.13848617,  0.05122235,  0.01080433,\n",
      "       -0.0385248 ,  0.07188522, -0.13732061,  0.11527563,  0.00430192,\n",
      "        0.11513952,  0.01504087, -0.00183213, -0.11781654, -0.00919915,\n",
      "       -0.09338227, -0.11878245,  0.12279342,  0.08435721, -0.11036345,\n",
      "        0.14752143,  0.02350337,  0.10246942, -0.18642919, -0.1284383 ,\n",
      "        0.19218195, -0.11681975,  0.01157606,  0.01807153, -0.12063645,\n",
      "       -0.07404594,  0.07729346, -0.09068179,  0.1218544 ,  0.03623401,\n",
      "       -0.05833344,  0.14212708, -0.06641879]), \n",
      "Layer: 0 \n",
      "Neuron: 21 \n",
      "Weights: array([-0.20359557,  0.0704656 ,  0.20735963, -0.04608172, -0.11190166,\n",
      "       -0.24817985,  0.14173703,  0.09907717,  0.35359463, -0.36638696,\n",
      "       -0.04701058,  0.03505317, -0.11681213,  0.52978249,  0.60088248,\n",
      "       -0.01866689,  0.15946046,  0.4589805 , -0.39979927,  0.05261652,\n",
      "       -0.09429344,  0.41803618, -0.47507724,  0.07316831, -0.10182465,\n",
      "        0.26004211, -0.00396025, -0.15675614,  0.01212538,  0.00131373,\n",
      "       -0.18876661, -0.0334252 ,  0.18624817,  0.15494531,  0.06632979,\n",
      "        0.04485158, -0.11862665,  0.28582317, -0.2103565 ,  0.14773308,\n",
      "       -0.1151959 , -0.18895302,  0.27534848, -0.10914782,  0.12575505,\n",
      "       -0.22492758, -0.03149419, -0.05665491,  0.25923994, -0.25242676,\n",
      "       -0.03311802,  0.18227966,  0.0432798 , -0.03165309,  0.02934485,\n",
      "        0.17100577, -0.02564727,  0.04133949]), \n",
      "Layer: 0 \n",
      "Neuron: 22 \n",
      "Weights: array([ 0.1139696 ,  0.28382042, -0.13940947,  0.36448938, -0.16394707,\n",
      "       -0.10013722, -0.1451579 ,  0.23264695, -0.20330601,  0.30027083,\n",
      "        0.03767744,  0.06271014, -0.16769961,  0.32893961,  0.0022105 ,\n",
      "       -0.31779302,  0.13767069,  0.12079334, -0.08378221,  0.03183081,\n",
      "       -0.1563941 ,  0.1231547 , -0.19056954, -0.00915962,  0.07015059,\n",
      "       -0.05977803, -0.19021741,  0.03547312, -0.12666119,  0.17331104,\n",
      "        0.2938783 , -0.06219196, -0.15929048,  0.10534223, -0.12743238,\n",
      "       -0.17521026,  0.14711135, -0.01221432, -0.10864516,  0.07915435,\n",
      "       -0.15526573, -0.06268011,  0.02334608,  0.00649501, -0.03140881,\n",
      "        0.23249681, -0.2524994 ,  0.12046918, -0.25865154,  0.07329097,\n",
      "       -0.12171018,  0.16924051,  0.27883457, -0.24337453, -0.09322893,\n",
      "        0.20147685,  0.12629932, -0.17113909]), \n",
      "Layer: 0 \n",
      "Neuron: 23 \n",
      "Weights: array([-0.02309237,  0.09547093, -0.02491241,  0.27596361, -0.01534376,\n",
      "       -0.12819994,  0.01894797, -0.0505177 ,  0.0706384 , -0.14219497,\n",
      "       -0.14112068, -0.11940609,  0.19027909,  0.17320726,  0.22738061,\n",
      "        0.22426511, -0.02810775,  0.06842211, -0.18808126, -0.05253515,\n",
      "        0.00528359,  0.08455117,  0.03067223,  0.02869247, -0.0524668 ,\n",
      "        0.00330909, -0.13706128, -0.05654875, -0.00131586, -0.00272454,\n",
      "        0.19476995,  0.07504949,  0.00640848, -0.3547189 ,  0.12186857,\n",
      "       -0.1638631 ,  0.14868803, -0.11995688,  0.10512735, -0.02996813,\n",
      "        0.20880911, -0.15394407, -0.14960479,  0.1014846 ,  0.04701549,\n",
      "        0.01404821,  0.0741163 ,  0.0380973 ,  0.10183499, -0.17667594,\n",
      "       -0.21851299,  0.21451361, -0.17214717,  0.1223663 , -0.01143475,\n",
      "        0.13095128,  0.05213219, -0.07099132]), \n",
      "Layer: 0 \n",
      "Neuron: 24 \n",
      "Weights: array([  2.36337895e-02,   7.77916706e-02,   1.02728857e-02,\n",
      "         7.07871844e-03,   1.20504819e-02,  -1.04960749e-02,\n",
      "         2.46573164e-02,  -9.96793440e-02,   1.30712003e-01,\n",
      "        -7.47713209e-02,   1.05196211e-01,  -1.72105490e-01,\n",
      "         2.81577370e-02,   1.45147125e-01,   1.93106833e-01,\n",
      "         3.90126797e-02,   2.00991090e-02,   9.52545840e-02,\n",
      "        -6.19814367e-02,   1.00159576e-01,   4.31572657e-02,\n",
      "         3.32007864e-05,   1.00429196e-01,  -1.41197870e-02,\n",
      "        -1.02449378e-01,   5.58538899e-02,   2.93010184e-03,\n",
      "         9.51417629e-03,  -2.98143001e-02,   4.87850287e-02,\n",
      "        -2.12063228e-03,  -1.40858642e-02,  -3.41680196e-03,\n",
      "         1.06852326e-01,   1.28069304e-01,   1.07575020e-01,\n",
      "         1.43091988e-01,   5.34491263e-02,  -6.80215103e-02,\n",
      "        -7.77339802e-02,  -4.91798403e-02,   1.72311647e-02,\n",
      "        -5.55686890e-02,  -5.98849933e-03,   6.68244116e-02,\n",
      "        -6.96243944e-02,   3.42465458e-02,  -8.89372932e-02,\n",
      "         1.07154519e-01,   6.05990337e-02,  -2.67913720e-02,\n",
      "        -5.28049893e-02,   2.12334054e-02,   6.80294826e-02,\n",
      "        -1.03429265e-01,   6.98026815e-02,  -1.74896083e-02,\n",
      "        -1.02101173e-01]), \n",
      "Layer: 0 \n",
      "Neuron: 25 \n",
      "Weights: array([ 0.30582574,  0.01843353, -0.15678778,  0.07661513, -0.28925585,\n",
      "       -0.04756242, -0.16494633, -0.07792076, -0.03271911,  0.03904737,\n",
      "        0.17182982, -0.0321994 ,  0.07131918,  0.05664779,  0.21541706,\n",
      "        0.27488283, -0.23159037, -0.03431352,  0.18309549, -0.20164721,\n",
      "        0.1579254 , -0.42066748,  0.33283225,  0.03774149,  0.19296641,\n",
      "        0.00356653,  0.0474107 , -0.09231863, -0.02055114, -0.04043848,\n",
      "       -0.19561423, -0.01732947,  0.07924713,  0.00151596,  0.14193188,\n",
      "        0.1077801 , -0.15853958, -0.25162966,  0.10544827, -0.10038909,\n",
      "        0.22392601, -0.01269003, -0.01628493,  0.06116559, -0.17019259,\n",
      "        0.25262576, -0.07659788, -0.06125177, -0.10619056,  0.02728243,\n",
      "        0.11629148, -0.26409819, -0.33503182,  0.28102864,  0.03545468,\n",
      "       -0.01877301, -0.17145832,  0.16930705]), \n",
      "Layer: 0 \n",
      "Neuron: 26 \n",
      "Weights: array([-0.1014813 , -0.16963528,  0.02217213,  0.12980458,  0.02463114,\n",
      "        0.14844809, -0.1011244 , -0.09502815,  0.18381983,  0.14477074,\n",
      "        0.05877576, -0.2036832 , -0.01750323, -0.03997348,  0.29127483,\n",
      "       -0.14002972,  0.13577892,  0.13937251, -0.07206336,  0.08355909,\n",
      "       -0.04735933, -0.03712015, -0.00311968,  0.08753601, -0.0278459 ,\n",
      "       -0.05328251,  0.13947084,  0.1072331 , -0.09090055, -0.09530694,\n",
      "       -0.06694208, -0.03113825,  0.12734952, -0.12211478, -0.13928594,\n",
      "        0.00037171,  0.00470361,  0.04061455,  0.06264171,  0.09466392,\n",
      "        0.00537837, -0.08236078, -0.23727645,  0.12994229,  0.03805089,\n",
      "       -0.09614075,  0.13826085, -0.09593712,  0.12044282,  0.04558612,\n",
      "       -0.06472674,  0.03574685,  0.22511616, -0.03331478, -0.12360771,\n",
      "       -0.09659956, -0.00229251,  0.02750608]), \n",
      "Layer: 0 \n",
      "Neuron: 27 \n",
      "Weights: array([ 0.02384474, -0.06588657,  0.16416293, -0.10394587,  0.15679413,\n",
      "       -0.13660647,  0.0737659 , -0.30822429,  0.05136296, -0.12001228,\n",
      "       -0.00047916, -0.0249042 , -0.09684075, -0.03446848,  0.22296548,\n",
      "        0.14314379, -0.03840841, -0.13018185,  0.04248014, -0.09295876,\n",
      "        0.07063961, -0.06997587, -0.0293465 ,  0.277615  , -0.13609668,\n",
      "        0.14014413,  0.07898987, -0.07586095, -0.15698906,  0.18923916,\n",
      "       -0.03564823, -0.19327629,  0.13821051, -0.15564879, -0.023872  ,\n",
      "        0.07101269, -0.02334734, -0.08343352,  0.13570508,  0.17536725,\n",
      "       -0.12673945,  0.03959324, -0.04930295,  0.07218064,  0.07527737,\n",
      "       -0.10703925,  0.14476437, -0.0027532 , -0.03837798,  0.00231581,\n",
      "        0.04091739, -0.11929861, -0.0047774 ,  0.02318663,  0.03148438,\n",
      "        0.03225087, -0.1099489 , -0.05404172]), \n",
      "Layer: 0 \n",
      "Neuron: 28 \n",
      "Weights: array([-0.12295254, -0.12327202,  0.10240574,  0.02517637, -0.04978435,\n",
      "        0.28562798, -0.29200292, -0.09811618,  0.0356237 , -0.1526245 ,\n",
      "        0.01349048,  0.07631279,  0.18321419, -0.49469536, -0.46588539,\n",
      "       -0.08661479,  0.34236589,  0.04400214,  0.05469811, -0.14389647,\n",
      "       -0.07065111,  0.09630594,  0.01928684, -0.16706367,  0.1756256 ,\n",
      "        0.08696592,  0.06676728, -0.07211547,  0.11419449, -0.10601897,\n",
      "       -0.13120883, -0.07896504,  0.08284641,  0.06962722,  0.030577  ,\n",
      "        0.04008389,  0.01345299, -0.08010822, -0.18092001, -0.06016432,\n",
      "        0.26142658, -0.13360203, -0.15599587, -0.09031227,  0.01648717,\n",
      "        0.0800371 , -0.10657003,  0.0473581 ,  0.05453978,  0.01517572,\n",
      "        0.0633752 ,  0.11551575,  0.02624564, -0.03014603,  0.05473284,\n",
      "       -0.06710086,  0.02492911, -0.02844988]), \n",
      "Layer: 0 \n",
      "Neuron: 29 \n",
      "Weights: array([ -2.36830684e-01,   6.35758923e-02,   5.58585120e-02,\n",
      "         1.65489301e-02,  -3.92957883e-02,  -3.21456923e-01,\n",
      "         1.52933350e-02,  -1.68414425e-01,  -4.70309341e-02,\n",
      "        -1.35153541e-01,  -6.66443913e-02,   7.46953899e-02,\n",
      "         1.61103716e-02,   3.36573554e-01,   1.16828114e-01,\n",
      "         2.07259054e-01,  -1.38022690e-01,  -2.36239914e-01,\n",
      "         9.08244393e-02,  -1.43614795e-01,  -5.30312705e-02,\n",
      "         5.98817195e-02,  -1.27270590e-01,   4.18403663e-02,\n",
      "         5.69719206e-02,   1.21643432e-02,  -1.08351901e-01,\n",
      "        -4.88473845e-02,   2.29707234e-01,  -8.30300954e-02,\n",
      "        -9.47406724e-02,   1.47479466e-01,   1.75564274e-01,\n",
      "        -2.47171319e-01,  -1.27146631e-01,   9.74816173e-02,\n",
      "        -6.30511391e-02,  -5.20718398e-02,  -8.66709088e-04,\n",
      "        -1.92754807e-02,  -6.07029533e-02,  -5.64014783e-02,\n",
      "        -1.40655270e-01,  -9.89474548e-02,  -1.68219157e-01,\n",
      "         6.61137844e-02,   5.79511253e-02,   9.27843242e-02,\n",
      "         1.54676257e-02,   1.64211341e-01,   1.99673527e-04,\n",
      "         1.22008567e-01,  -1.79718689e-01,   3.04449060e-01,\n",
      "        -5.57665330e-02,   1.68099648e-01,   4.36943917e-02,\n",
      "        -2.57935751e-02]), \n",
      "\n",
      "Layer: 1 \n",
      "Neuron: 0 \n",
      "Weights: array([-0.54905075,  0.0233951 ,  0.59967762,  0.15437549,  0.19384414,\n",
      "        0.10873611, -0.5300503 ,  0.43005526, -0.87864675,  0.33215469,\n",
      "        0.52739854, -0.48182557,  0.33470144, -0.26954712, -0.13209057,\n",
      "       -0.09282745,  0.64174497, -0.48509682, -0.33153582,  0.61108144,\n",
      "        0.46925248, -0.59405219, -0.80448406, -0.47116793,  0.02168755,\n",
      "       -0.73681816,  0.21441369, -0.25030537,  0.51562045, -0.22650926]), \n",
      "Layer: 1 \n",
      "Neuron: 1 \n",
      "Weights: array([ 1.00399379,  0.57927759, -0.29972455, -0.82539306, -0.18199797,\n",
      "        0.39159176,  0.45945982,  0.0437427 ,  0.08022561, -0.44290821,\n",
      "       -0.14664835,  0.52697556,  0.00893   ,  0.41419069,  0.11682128,\n",
      "        0.51852043, -0.42514591,  0.64511417,  0.68931904,  0.06739411,\n",
      "        0.05352608,  1.22495198,  0.70724008,  0.52245705,  0.18523054,\n",
      "        0.70549838,  0.41581267,  0.64368937, -0.4669924 ,  0.5674846 ]), \n",
      "Layer: 1 \n",
      "Neuron: 2 \n",
      "Weights: array([-0.16569587, -0.34927903, -0.35429543,  0.79873109,  0.10540386,\n",
      "       -0.2069125 , -0.27692113, -0.27845907,  0.49978441, -0.50020969,\n",
      "       -0.13207493, -0.08109648, -0.5614363 , -0.1341601 , -0.49903697,\n",
      "       -0.18371248, -0.34733415, -0.15500388, -0.48676108, -0.4240004 ,\n",
      "       -0.22093245, -0.30540355,  0.04928069, -0.26537517,  0.01820075,\n",
      "       -0.39596827, -0.48543532,  0.07184454,  0.14504137, -0.0996761 ]), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer, Neuron, and Weights for standardized design matrix.\")\n",
    "for i in range(len(mlp1.coefs_)):\n",
    "    n_neurons_per_layer = mlp1.coefs_[i].shape[1]\n",
    "    for j in range(n_neurons_per_layer):\n",
    "        w = mlp1.coefs_[i][:,j]\n",
    "        print(\"Layer: %r \\nNeuron: %r \\nWeights: %r\" %(i, j, w) , end=\", \")\n",
    "        print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "This step is to make predictions on the test set we set aside that the model has yet to see and was not trianed on. Returns a data frame of the actaul *y* values and the perdicted *y* values. This data frame helps us to visually see where our model made incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_nn_stan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_act  y_nn_stan\n",
       "Obs                  \n",
       "0        1          1\n",
       "1        1          1\n",
       "2        1          1\n",
       "3        1          1\n",
       "4        1          1\n",
       "5        1          1\n",
       "6        1          1\n",
       "7        0          0\n",
       "8        1          1\n",
       "9        1          1\n",
       "10       1          1\n",
       "11       1          1\n",
       "12       1          1\n",
       "13       0          1\n",
       "14       1          1\n",
       "15       1          1\n",
       "16       1          1\n",
       "17       0          1\n",
       "18       1          1\n",
       "19       1          1\n",
       "20       1          1\n",
       "21       1          1\n",
       "22       1          1\n",
       "23       1          1\n",
       "24       1          1\n",
       "25       1          1\n",
       "26       0          0\n",
       "27       1          1\n",
       "28       1          1\n",
       "29       1          1\n",
       "..     ...        ...\n",
       "185      1          1\n",
       "186      1          1\n",
       "187      0          1\n",
       "188      1          1\n",
       "189      1          1\n",
       "190      1          0\n",
       "191      0          1\n",
       "192      1          1\n",
       "193      1          1\n",
       "194      1          1\n",
       "195      0          0\n",
       "196      1          1\n",
       "197      1          1\n",
       "198      1          0\n",
       "199      1          1\n",
       "200      1          1\n",
       "201      1          1\n",
       "202      1          0\n",
       "203      1          1\n",
       "204      1          1\n",
       "205      1          1\n",
       "206      1          1\n",
       "207      1          1\n",
       "208      1          1\n",
       "209      1          1\n",
       "210      0          1\n",
       "211      1          1\n",
       "212      1          1\n",
       "213      1          1\n",
       "214      1          1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pred1 = nn1.predict(X1_test)\n",
    "\n",
    "pred = pd.DataFrame(list(zip(y1_test, nn_pred1)), columns=['y_act','y_nn_stan'])\n",
    "pred.index.name = 'Obs'\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Accuracy, confusion matrix, and classification reports are returned for the standardized design matirx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Standardized Neural Network model is:  0.906976744186\n",
      "\n",
      "\n",
      "Standardized Neural Network Confusion Matrix: \n",
      "          Fail(0)  Pass(1)  Inc(2)\n",
      "Fail(0)       14        9       0\n",
      "Pass(1)        7      180       0\n",
      "Inc(2)         2        2       1\n",
      "\n",
      "\n",
      "Classification report for standardized design matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.61      0.61        23\n",
      "          1       0.94      0.96      0.95       187\n",
      "          2       1.00      0.20      0.33         5\n",
      "\n",
      "avg / total       0.91      0.91      0.90       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm_nn1 = pd.DataFrame(metrics.confusion_matrix(y1_test, nn_pred1), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "\n",
    "print (\"The accuracy of the Standardized Neural Network model is: \", nn1.score(X1_test,y1_test))\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Standardized Neural Network Confusion Matrix: \\n\", cm_nn1)\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Classification report for standardized design matrix:\\n\", metrics.classification_report(y1_test,nn_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
