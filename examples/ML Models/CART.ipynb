{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees (CART)\n",
    "Classifing student success data by means of the [Decision Tree Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) from the sklearn module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Import the data into a pandas dataframe. Get dummy variables for each categorical predictor in the data set and return the design matirx. Create a normalized and standardized design matrix as well to compare model preformance. Convert response variable to three classes *0 , 1,* and *2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\006988889-SA\\Downloads\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Users\\006988889-SA\\Downloads\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('student-por2.csv')\n",
    "df = pd.get_dummies(df)#, drop_first=True)\n",
    "\n",
    "def response_conv(arr):\n",
    "    new = []\n",
    "    for i in arr:\n",
    "        if (i > 0 and i < 10):           # condition where student failed\n",
    "            new.append(0)                 \n",
    "                                          \n",
    "        elif (i >= 10):                   # condition where student passed\n",
    "            new.append(1)                 \n",
    "    \n",
    "        else:                             # condition where student received an incomplete\n",
    "            new.append(2)\n",
    "    return(new)                           # 1-dimensional response varibale returned\n",
    "\n",
    "X = df.drop('G3',1)                       # This is the design matrix\n",
    "y = list(df.G3)                           # This is the discrete response vector\n",
    "y_new = response_conv(y)                  # This is the multinomial response vector\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X,y)\n",
    "\n",
    "model = SelectFromModel(clf,prefit=True)\n",
    "newX = model.transform(X)\n",
    "\n",
    "X_scale = preprocessing.scale(newX)\n",
    "X_norm = preprocessing.normalize(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Parameters for Decision Tree Classifier Algorithm\n",
    "We choose the combination of parameters that minimize the negative log loss metric. Return optimal parameters and total run time for the cross validating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(newX, y_new, test_size=0.33, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_scale, y_new, test_size=0.33, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_norm, y_new, test_size=0.33, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "combos = cartesian([['gini','entropy'],['best','random'],['auto','log2'],np.arange(1,(X1_train.shape[0]-1))])\n",
    "\n",
    "def opt(X,y):\n",
    "    log_lo = []\n",
    "\n",
    "    for c,s,mf,md in combos:\n",
    "        dt = DecisionTreeClassifier(criterion=c,splitter=s,max_features=mf,max_depth=int(md))\n",
    "        #fits = dt.fit(X,y)\n",
    "        #y_hat = fits.predict(X,y)\n",
    "        scores = cross_val_score(dt, X, y, cv=10, scoring='neg_log_loss')\n",
    "        log_lo.append(scores.mean())\n",
    "    \n",
    "    #MSE = [1 - x for x in cv_scores]\n",
    "    opt_ = combos[log_lo.index(min(log_lo))]\n",
    "    return(opt_)\n",
    "\n",
    "c1,s1,mf1,md1 = opt(X1_train,y1_train)\n",
    "c2,s2,mf2,md2 = opt(X2_train,y2_train)\n",
    "c3,s3,mf3,md3 = opt(X3_train,y3_train)\n",
    "\n",
    "print (\"The optimal criterion, splitter, max_features and max_depth are %s, %s, %s, and %r respectively for Non-standardized design matrix.\" % (str(c1),str(s1),str(mf1),int(md1)))\n",
    "print (\"The optimal criterion, splitter, max_features and max_depth are %s, %s, %s, and %r respectively for Standardized design matrix.\" % (str(c2),str(s2),str(mf2),int(md2)))\n",
    "print (\"The optimal criterion, splitter, max_features and max_depth are %s, %s, %s, and %r respectively for Normalized design matrix.\" % (str(c3),str(s3),str(mf3),int(md3)))\n",
    "print(\"Run time: %r minutes\" % (int(time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict\n",
    "After tuning model parameters to be optimal we fit each design matrix to its optimal model. Predictions are made and returned in a data frame for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeClassifier(criterion=c1,splitter=s1,max_features=mf1,max_depth=int(md1)).fit(X1_train,y1_train)\n",
    "dt2 = DecisionTreeClassifier(criterion=c2,splitter=s2,max_features=mf2,max_depth=int(md2)).fit(X2_train,y2_train)\n",
    "dt3 = DecisionTreeClassifier(criterion=c3,splitter=s3,max_features=mf3,max_depth=int(md3)).fit(X3_train,y3_train)\n",
    "\n",
    "dt_pred1 = dt1.predict(X1_test)\n",
    "dt_pred2 = dt2.predict(X2_test)\n",
    "dt_pred3 = dt3.predict(X3_test)\n",
    "\n",
    "pred = pd.DataFrame(list(zip(y1_test, dt_pred1, dt_pred2, dt_pred3)), columns=['y_act','y_dt','y_dt_stan','y_dt_norm'])\n",
    "pred.index.name = 'Obs'\n",
    "\n",
    "# remove comment below to save the predictions in a csv file and view the full data frame in excel\n",
    "#pred.to_csv(\"preds.csv\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Accuracy, confusion matrix, and classification reports are returned for each design matirx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_dt1 = pd.DataFrame(metrics.confusion_matrix(y1_test, dt_pred1), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "cm_dt2 = pd.DataFrame(metrics.confusion_matrix(y2_test, dt_pred2), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "cm_dt3 = pd.DataFrame(metrics.confusion_matrix(y3_test, dt_pred3), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "\n",
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "for i in y1_train:\n",
    "    if i == 0:\n",
    "        zero += 1\n",
    "    elif i == 1:\n",
    "        one += 1\n",
    "    else:\n",
    "        two += 1\n",
    "num1 = round(zero/len(y1_train),2)\n",
    "num2 = round(one/len(y1_train),2)\n",
    "num3 = round(two/len(y1_train),2)\n",
    "print(\"The response vector has the following distribution: \\nzeros: %r \\nones: %r \\ntwos: %r\" % (num1,num2,num3))\n",
    "print(\"\\n\")\n",
    "\n",
    "print (\"The accuracy of the Non-standardized Decision Tree model is: \", dt1.score(X1_test,y1_test))\n",
    "print (\"\\n\")\n",
    "print (\"The accuracy of the Standardized Decision Tree model is: \", dt2.score(X2_test,y2_test))\n",
    "print (\"\\n\")\n",
    "print (\"The accuracy of the Normalized Decision Tree model is: \", dt3.score(X3_test,y3_test))\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Non-standardized Decision Tree Confusion Matrix: \\n\", cm_dt1)\n",
    "print (\"\\n\")\n",
    "print(\"Standardized Decision Tree Confusion Matrix: \\n\", cm_dt2)\n",
    "print (\"\\n\")\n",
    "print(\"Normalized Decision Tree Confusion Matrix: \\n\", cm_dt3)\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Classification report for Non-standardized design matrix:\\n\", metrics.classification_report(y1_test,dt_pred1))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for standardized design matrix:\\n\", metrics.classification_report(y2_test,dt_pred2))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for Normalized design matrix:\\n\", metrics.classification_report(y3_test,dt_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
