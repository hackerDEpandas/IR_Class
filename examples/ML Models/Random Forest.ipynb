{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "Classifing student success data by means of the [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from the sklearn module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Import the data into a pandas dataframe. Get dummy variables for each categorical predictor in the data set and return the design matirx. Create a normalized and standardized design matrix as well to compare model preformance. Convert response variable to three classes *0 , 1,* and *2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\006988889-SA\\Downloads\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Users\\006988889-SA\\Downloads\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('student-por2.csv')\n",
    "df = pd.get_dummies(df)#, drop_first=True)\n",
    "\n",
    "def response_conv(arr):\n",
    "    new = []\n",
    "    for i in arr:\n",
    "        if (i > 0 and i < 10):           # condition where student failed\n",
    "            new.append(0)                 \n",
    "                                          \n",
    "        elif (i >= 10):                   # condition where student passed\n",
    "            new.append(1)                 \n",
    "    \n",
    "        else:                             # condition where student received an incomplete\n",
    "            new.append(2)\n",
    "    return(new)                           # 1-dimensional response varibale returned\n",
    "\n",
    "X = df.drop('G3',1)                       # This is the design matrix\n",
    "y = list(df.G3)                           # This is the discrete response vector\n",
    "y_new = response_conv(y)                  # This is the multinomial response vector\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X,y)\n",
    "\n",
    "model = SelectFromModel(clf,prefit=True)\n",
    "newX = model.transform(X)\n",
    "\n",
    "X_scale = preprocessing.scale(newX)\n",
    "X_norm = preprocessing.normalize(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Training Sets and Optimal Number of Trees and Features\n",
    "To train the model and later test, we must split each design matrix and response vector into training and test sets. The fucntion *opt* finds the optimal parameters for *number of trees* and *number of features* to be used in the bagging process of the model. Optimal is decided based on the parameters used in the model that returns the smallest mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(newX, y_new, test_size=0.33, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_scale, y_new, test_size=0.33, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_norm, y_new, test_size=0.33, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "combos = cartesian([['auto','log2',None],np.arange(10,101,10)])\n",
    "\n",
    "def opt(X,y):\n",
    "    log_lo = []\n",
    "\n",
    "    for m,t in combos:\n",
    "        rf = RandomForestClassifier(n_estimators=t,max_features=m)\n",
    "        scores = cross_val_score(rf, X, y, cv=10, scoring='neg_log_loss')\n",
    "        log_lo.append(scores.mean())\n",
    "    \n",
    "    #MSE = [1 - x for x in cv_scores]\n",
    "    opt_k = combos[log_lo.index(min(log_lo))]\n",
    "    return(opt_k)\n",
    "\n",
    "m1,t1 = opt(X1_train,y1_train)\n",
    "m2,t2 = opt(X2_train,y2_train)\n",
    "m3,t3 = opt(X3_train,y3_train)\n",
    "\n",
    "print (\"The optimal number of trees and number of features to consider is %r and %r respectively for Non-standardized design matrix.\" % (int(t1),str(m1)))\n",
    "print (\"The optimal number of trees and number of features to consider is %r and %r respectively for Non-standardized design matrix.\" % (int(t2),str(m2)))\n",
    "print (\"The optimal number of trees and number of features to consider is %r and %r respectively for Non-standardized design matrix.\" % (int(t3),str(m3)))\n",
    "print(\"Run time: %r minutes\" % (int(time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict\n",
    "After tuning model parameters to be optimal we fit each design matrix to its optimal model. Predictions are made and returned in a data frame for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=t1,max_features=m1,random_state=42).fit(X1_train,y1_train)\n",
    "rf2 = RandomForestClassifier(n_estimators=t2,max_features=m2,random_state=42).fit(X2_train,y2_train)\n",
    "rf3 = RandomForestClassifier(n_estimators=t3,max_features=m3,random_state=42).fit(X3_train,y3_train)\n",
    "\n",
    "rf_pred1 = rf1.predict(X1_test)\n",
    "rf_pred2 = rf2.predict(X2_test)\n",
    "rf_pred3 = rf3.predict(X3_test)\n",
    "\n",
    "pred = pd.DataFrame(list(zip(y1_test, rf_pred1, rf_pred2, rf_pred3)), columns=['y_act','y_rf','y_rf_stan','y_rf_norm'])\n",
    "pred.index.name = 'Obs'\n",
    "\n",
    "# remove comment below to save the predictions in a csv file and view the full data frame in excel\n",
    "#pred.to_csv(\"preds.csv\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Accuracy, confusion matrix, and classification reports are returned for each design matirx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf1 = pd.DataFrame(metrics.confusion_matrix(y1_test, rf_pred1), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "cm_rf2 = pd.DataFrame(metrics.confusion_matrix(y2_test, rf_pred2), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "cm_rf3 = pd.DataFrame(metrics.confusion_matrix(y3_test, rf_pred3), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "\n",
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "for i in y1_train:\n",
    "    if i == 0:\n",
    "        zero += 1\n",
    "    elif i == 1:\n",
    "        one += 1\n",
    "    else:\n",
    "        two += 1\n",
    "num1 = round(zero/len(y1_train),2)\n",
    "num2 = round(one/len(y1_train),2)\n",
    "num3 = round(two/len(y1_train),2)\n",
    "print(\"The response vector has the following distribution: \\nzeros: %r \\nones: %r \\ntwos: %r\" % (num1,num2,num3))\n",
    "print(\"\\n\")\n",
    "\n",
    "print (\"The accuracy of the Non-standardized Random Forest model is: \", rf1.score(X1_test,y1_test))\n",
    "print (\"\\n\")\n",
    "print (\"The accuracy of the Standardized Random Forest model is: \", rf2.score(X2_test,y2_test))\n",
    "print (\"\\n\")\n",
    "print (\"The accuracy of the Normalized Random Forest model is: \", rf3.score(X3_test,y3_test))\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Non-standardized Random Forest Confusion Matrix: \\n\", cm_rf1)\n",
    "print (\"\\n\")\n",
    "print(\"Standardized Random Forest Confusion Matrix: \\n\", cm_rf2)\n",
    "print (\"\\n\")\n",
    "print(\"Normalized Random Forest Confusion Matrix: \\n\", cm_rf3)\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Classification report for Non-standardized design matrix:\\n\", metrics.classification_report(y1_test,rf_pred1))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for standardized design matrix:\\n\", metrics.classification_report(y2_test,rf_pred2))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for Normalized design matrix:\\n\", metrics.classification_report(y3_test,rf_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
