{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Classifing student success data by means of the [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) from the sklearn module. The data set comes from UCI's machine learning repository and can be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00320/). A description of the data can be found [here](https://archive.ics.uci.edu/ml/datasets/student+performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Import the data into a pandas dataframe. Get dummy variables for each categorical predictor in the data set and return the design matirx. Create a normalized design matrix as well to compare model preformance. Convert response variable to three classes *0 (fail) , 1 (pass),* and *2 (incomplete)*. A student is put into the passing class if they got a score bigger or equal to 10, the failing class if they got a score below 10 but above 0, and the incomplete calss if the student received a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "df = pd.read_csv('student-por2.csv')\n",
    "df = pd.get_dummies(df)#, drop_first=True)\n",
    "\n",
    "def response_conv(arr):\n",
    "    new = []\n",
    "    for i in arr:\n",
    "        if (i > 0 and i < 10):           # condition where student failed\n",
    "            new.append(0)                 \n",
    "                                          \n",
    "        elif (i >= 10):                   # condition where student passed\n",
    "            new.append(1)                 \n",
    "    \n",
    "        else:                             # condition where student received an incomplete\n",
    "            new.append(2)\n",
    "    return(new)                           # 1-dimensional response varibale returned\n",
    "\n",
    "X = df.drop('G3',1)                       # this is the design matrix\n",
    "y = list(df.G3)                           # this is the discrete response vector\n",
    "y_new = response_conv(y)                  # this is the multinomial response vector\n",
    "X_norm = preprocessing.normalize(X)       # this is the normalized design matrix\n",
    "\n",
    "random.seed(42)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y_new, test_size=0.33, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_norm, y_new, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Niave Accuracy\n",
    "Before we start training and selecting parametrs for our model, we must find the distribution of the classes amongst the response variable. Depnding on which class is the dominate class, our model should preform better than just guessing the dominate class for each observation. For example, if the dominate class is 1 and 1's comprise of 83% of the response data, then our model should have higher than 83% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response vector has the following distribution: \n",
      "zeros: 23 zeros comprising of 10.7 percent of the response data. \n",
      "ones: 187 ones comprising of 86.98 percent of the response data. \n",
      "twos: 5 twos comprising of 2.33 percent of the response data.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "\n",
    "for i in y1_test:\n",
    "    if i == 0:\n",
    "        zero += 1\n",
    "    elif i == 1:\n",
    "        one += 1\n",
    "    else:\n",
    "        two += 1\n",
    "\n",
    "num1 = round((zero/len(y1_test))*100,2)\n",
    "num2 = round((one/len(y1_test))*100,2)\n",
    "num3 = round((two/len(y1_test))*100,2)\n",
    "print(\"The response vector has the following distribution: \\nzeros: %r zeros comprising of %r percent of the response data. \\nones: %r ones comprising of %r percent of the response data. \\ntwos: %r twos comprising of %r percent of the response data.\" % (zero,num1,one,num2,two,num3))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Alpha \n",
    "By means of 10-Fold cross validation we return optimal values of alpha for each design matrix. Optimal is decided by selecting alphas that maximize the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal alpha value is 0.10000000000000001 for Non-standardized design matrix.\n",
      "The optimal alpha value is 0.10000000000000001 for Normalized design matrix.\n"
     ]
    }
   ],
   "source": [
    "def opt(X,y):\n",
    "    acc = []\n",
    "    alphas = 10.0**-np.arange(1,5)\n",
    "    for a in alphas:\n",
    "        nb = MultinomialNB(alpha=a)\n",
    "        scores = cross_val_score(nb, X, y, cv=10, scoring='accuracy')\n",
    "        acc.append(scores.mean())\n",
    "    \n",
    "\n",
    "    opt_ = alphas[acc.index(max(acc))]\n",
    "    return(opt_)\n",
    "\n",
    "a1 = opt(X1_train,y1_train)\n",
    "a3 = opt(X3_train,y3_train)\n",
    "\n",
    "print(\"The optimal alpha value is %r for Non-standardized design matrix.\" % a1)\n",
    "print(\"The optimal alpha value is %r for Normalized design matrix.\" % a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict\n",
    "Fit a model for both the non-normalized and normalized design matrix using optimal alphas. Predict using the respective testing set and compare predictions into a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_nb</th>\n",
       "      <th>y_nb_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_act  y_nb  y_nb_norm\n",
       "Obs                        \n",
       "0        1     1          1\n",
       "1        1     1          1\n",
       "2        1     1          1\n",
       "3        1     1          1\n",
       "4        1     1          1\n",
       "5        1     1          1\n",
       "6        1     1          1\n",
       "7        0     0          1\n",
       "8        1     1          1\n",
       "9        1     1          1\n",
       "10       1     1          1\n",
       "11       1     1          1\n",
       "12       1     1          1\n",
       "13       0     1          1\n",
       "14       1     1          1\n",
       "15       1     1          1\n",
       "16       1     1          1\n",
       "17       0     0          1\n",
       "18       1     1          1\n",
       "19       1     1          1\n",
       "20       1     1          1\n",
       "21       1     1          1\n",
       "22       1     1          1\n",
       "23       1     1          1\n",
       "24       1     1          1\n",
       "25       1     1          1\n",
       "26       0     0          1\n",
       "27       1     1          1\n",
       "28       1     1          1\n",
       "29       1     1          1\n",
       "..     ...   ...        ...\n",
       "185      1     1          1\n",
       "186      1     1          1\n",
       "187      0     0          1\n",
       "188      1     1          1\n",
       "189      1     1          1\n",
       "190      1     0          1\n",
       "191      0     0          1\n",
       "192      1     1          1\n",
       "193      1     1          1\n",
       "194      1     1          1\n",
       "195      0     1          1\n",
       "196      1     1          1\n",
       "197      1     1          1\n",
       "198      1     0          1\n",
       "199      1     0          1\n",
       "200      1     1          1\n",
       "201      1     1          1\n",
       "202      1     0          1\n",
       "203      1     1          1\n",
       "204      1     1          1\n",
       "205      1     1          1\n",
       "206      1     1          1\n",
       "207      1     1          1\n",
       "208      1     1          1\n",
       "209      1     1          1\n",
       "210      0     0          1\n",
       "211      1     0          1\n",
       "212      1     1          1\n",
       "213      1     1          1\n",
       "214      1     1          1\n",
       "\n",
       "[215 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb1 = MultinomialNB(alpha=a1).fit(X1_train,y1_train)\n",
    "nb3 = MultinomialNB(alpha=a3).fit(X3_train,y3_train)\n",
    "\n",
    "nb_pred1 = nb1.predict(X1_test)\n",
    "nb_pred3 = nb3.predict(X3_test)\n",
    "\n",
    "pred = pd.DataFrame(list(zip(y1_test, nb_pred1, nb_pred3)), columns=['y_act','y_nb','y_nb_norm'])\n",
    "pred.index.name = 'Obs'\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Accuracy, confusion matrix, and classification reports are returned for each design matirx. We see that the non-normalized design matrix yields accuracy lower than the niave accuracy, so it should not be considered as the final model. In fact nor should the normalized design matrix. Notice that with the normalized design matrix are model only guesses the dominate calss for each observation. Therefore neither model will be considered for this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Non-standardized Random Forest model is:  0.855813953488\n",
      "\n",
      "\n",
      "The accuracy of the Normalized Random Forest model is:  0.86976744186\n",
      "\n",
      "\n",
      "Non-standardized Random Forest Confusion Matrix: \n",
      "          Fail(0)  Pass(1)  Inc(2)\n",
      "Fail(0)       12        9       2\n",
      "Pass(1)       19      168       0\n",
      "Inc(2)         1        0       4\n",
      "\n",
      "\n",
      "Normalized Random Forest Confusion Matrix: \n",
      "          Fail(0)  Pass(1)  Inc(2)\n",
      "Fail(0)        0       23       0\n",
      "Pass(1)        0      187       0\n",
      "Inc(2)         0        5       0\n",
      "\n",
      "\n",
      "Classification report for Non-standardized design matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.52      0.44        23\n",
      "          1       0.95      0.90      0.92       187\n",
      "          2       0.67      0.80      0.73         5\n",
      "\n",
      "avg / total       0.88      0.86      0.87       215\n",
      "\n",
      "\n",
      "\n",
      "Classification report for Normalized design matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        23\n",
      "          1       0.87      1.00      0.93       187\n",
      "          2       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.76      0.87      0.81       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\006988889-SA\\Downloads\\conda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cm_nb1 = pd.DataFrame(metrics.confusion_matrix(y1_test, nb_pred1), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "cm_nb3 = pd.DataFrame(metrics.confusion_matrix(y3_test, nb_pred3), index = ['Fail(0)','Pass(1)','Inc(2)'],columns=['Fail(0)','Pass(1)','Inc(2)'])\n",
    "\n",
    "print (\"The accuracy of the Non-standardized Random Forest model is: \", nb1.score(X1_test,y1_test))\n",
    "print (\"\\n\")\n",
    "print (\"The accuracy of the Normalized Random Forest model is: \", nb3.score(X3_test,y3_test))\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Non-standardized Random Forest Confusion Matrix: \\n\", cm_nb1)\n",
    "print (\"\\n\")\n",
    "print(\"Normalized Random Forest Confusion Matrix: \\n\", cm_nb3)\n",
    "print (\"\\n\")\n",
    "\n",
    "print(\"Classification report for Non-standardized design matrix:\\n\", metrics.classification_report(y1_test,nb_pred1))\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for Normalized design matrix:\\n\", metrics.classification_report(y3_test,nb_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
